{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "200361138_experiment_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDRi-QTW-NzX",
        "outputId": "c054f83d-c761-46a4-f6fa-502c7abe538c"
      },
      "source": [
        "pip install eli5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "  Downloading eli5-0.11.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102 kB 40.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 106 kB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "MyKpJH9Z-PKC",
        "outputId": "1330c4a8-71d5-4423-8f9b-5c7dff0e8bf0"
      },
      "source": [
        "pip install pdpbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdpbox\n",
            "  Downloading PDPbox-0.2.1.tar.gz (34.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.0 MB 41 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pdpbox) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pdpbox) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pdpbox) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pdpbox) (1.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from pdpbox) (5.4.8)\n",
            "Collecting matplotlib==3.1.1\n",
            "  Downloading matplotlib-3.1.1-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 6.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pdpbox) (0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1->pdpbox) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1->pdpbox) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1->pdpbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1->pdpbox) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.1.1->pdpbox) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pdpbox) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pdpbox) (0.22.2.post1)\n",
            "Building wheels for collected packages: pdpbox\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.1-py3-none-any.whl size=35758225 sha256=5f0ccffdfd62ceb989b8a470d7158fa4962aa3237c88dc92c03cc21c82c25a46\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/d0/1a/b80035625c53131f52906a6fc4dd690d8efd2bf8af6a4015eb\n",
            "Successfully built pdpbox\n",
            "Installing collected packages: matplotlib, pdpbox\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.1 pdpbox-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GroS88YN-IhZ",
        "outputId": "4f951f2a-663e-4b7f-f5f5-afbaa23fdb50"
      },
      "source": [
        "#Importing all the necessary Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import eli5\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from pdpbox import pdp, info_plots"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prf6IuZG-KK7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN9g2Bfr-Ihk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_GR8KhK-Ihm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gxt5Lwe-Iho"
      },
      "source": [
        "#Loading training and test data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Customer Transaction Prediction/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Customer Transaction Prediction/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG-0iU2s-Ihq"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUELkZCy-Ihs"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7RtJaWS-Ihu"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKGfwA5E-Ihy"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK6DouNe-Ih0"
      },
      "source": [
        "train_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzYsyNpl-Ih3"
      },
      "source": [
        "test_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sihBYgZD-Ih-"
      },
      "source": [
        "# Function for finding missing values and datatypes of the features\n",
        "\n",
        "def missing_data(data):\n",
        "    missing = data.isnull().sum()\n",
        "    df = pd.concat([missing], axis =1 , keys = ['Missing Values'])\n",
        "    types = []\n",
        "    for col in data.columns:\n",
        "        dtype = str(data[col].dtype)\n",
        "        types.append(dtype)\n",
        "    df['Types'] = types\n",
        "    return(np.transpose(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu0iFaHV-IiA"
      },
      "source": [
        "missing_data(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2Fw55Ib-IiC"
      },
      "source": [
        "missing_data(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9wnlWcP-IiE"
      },
      "source": [
        "sns.countplot(train_data['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgSIIlAf-IiF"
      },
      "source": [
        "It can be seen that out data is imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S3QNrPx-IiG"
      },
      "source": [
        "print(\"{}% target values with 1\". format(100 * train_data[\"target\"].value_counts()[1]/train_data.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc-A8bcZ-IiG"
      },
      "source": [
        "f, ax = plt.subplots(1, 2, figsize=(18,8))\n",
        "train_data['target'].value_counts().plot.pie(explode=[0,0.1],autopct = '%1.1f%%', ax = ax[0], shadow = True)\n",
        "ax[0].set_title('target')\n",
        "ax[0].set_ylabel('')\n",
        "sns.countplot('target', data=train_data,ax=ax[1])\n",
        "ax[1].set_title('target')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyB7SCcu-IiG"
      },
      "source": [
        "train_data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bu6qA8b-IiH"
      },
      "source": [
        "print(\"Skewness: %f \" % train_data['target'].skew())\n",
        "print(\"Kurtosis: %f\" % train_data['target'].kurt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc6_HEjP-IiH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ4fUYNo-IiH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NNsu_Gy-IiH"
      },
      "source": [
        "Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5W3S7Q1-IiH"
      },
      "source": [
        "train_features = train_data.columns.values[2:202]\n",
        "test_features = test_data.columns.values[1:201]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOvLiJol-IiI"
      },
      "source": [
        "unique_train = []\n",
        "unique_test = []\n",
        "for feature in train_features:\n",
        "    train_values = train_data[feature].value_counts()\n",
        "    unique_train.append([feature, train_values.max(), train_values.idxmax()])\n",
        "for feature in test_features:\n",
        "    test_values = test_data[feature].value_counts()\n",
        "    unique_test.append([feature, test_values.max(), test_values.idxmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlcmSkPv-IiI"
      },
      "source": [
        "np.transpose((pd.DataFrame(unique_train, columns = ['Feature', 'Max Duplicates', 'Value']))\n",
        "             .sort_values(by = 'Max Duplicates', ascending = False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0WHY6-g-IiI"
      },
      "source": [
        "np.transpose((pd.DataFrame(unique_test, columns = ['Feature', 'Max Duplicates', 'Value']))\n",
        "             .sort_values(by = 'Max Duplicates', ascending = False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcqFjlri-IiI"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSn2g6n3-IiJ"
      },
      "source": [
        "for df in [train_data]:\n",
        "    df['sum'] = df[train_features].sum(axis=1)\n",
        "    df['min'] = df[train_features].min(axis=1)\n",
        "    df['max'] = df[train_features].max(axis=1)\n",
        "    df['mean'] = df[train_features].mean(axis=1)\n",
        "    df['std'] = df[train_features].std(axis=1)\n",
        "    df['skew'] = df[train_features].skew(axis=1)\n",
        "    df['kurt'] = df[train_features].kurtosis(axis=1)\n",
        "    df['median'] = df[train_features].median(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qsjpt95-IiJ"
      },
      "source": [
        "train_data[train_data.columns[202:]].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_n9SPRv-IiJ"
      },
      "source": [
        "for df in [test_data]:\n",
        "    df['sum'] = df[test_features].sum(axis=1)\n",
        "    df['min'] = df[test_features].min(axis=1)\n",
        "    df['max'] = df[test_features].max(axis=1)\n",
        "    df['mean'] = df[test_features].mean(axis=1)\n",
        "    df['std'] = df[test_features].std(axis=1)\n",
        "    df['skew'] = df[test_features].skew(axis=1)\n",
        "    df['kurt'] = df[test_features].kurtosis(axis=1)\n",
        "    df['median'] = df[test_features].median(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKHw1BKP-IiJ"
      },
      "source": [
        "test_data[test_data.columns[201:]].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iSfT3s7-IiK"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AACS8gmC-IiK"
      },
      "source": [
        "cols = ['target', 'ID_code', 'sum', 'min', 'max', 'mean', 'std', 'skew', 'kurt', 'median']\n",
        "X = train_data.drop(cols,axis=1)\n",
        "y = train_data['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKMj5kQ1ABx7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRkcAU_j-IiK"
      },
      "source": [
        "X_test = test_data.drop(\"ID_code\", axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4A2Jg0e-IiK"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X,y, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGSANlAY-IiK"
      },
      "source": [
        "logistic_clf = LogisticRegression().fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UjzSnt--IiK"
      },
      "source": [
        "preds = logistic_clf.predict(x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiS3R9YN-IiL"
      },
      "source": [
        "metrics.mean_absolute_error(y_val, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoiRyETO-IiL"
      },
      "source": [
        "metrics.mean_squared_error(y_val, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVvc7BiG-IiL"
      },
      "source": [
        "print(classification_report(y_val, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giliRs1X-IiL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfnP8lGN-IiM"
      },
      "source": [
        "from eli5.sklearn import PermutationImportance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZgCLVIT-IiM"
      },
      "source": [
        "perm = PermutationImportance(logistic_clf, random_state=1).fit(x_val,y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3hqcF4Z-IiM"
      },
      "source": [
        "eli5.show_weights(perm, feature_names = x_val.columns.tolist(), top = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE_QXB3E-IiM"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X,y, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6wFznSB-IiM"
      },
      "source": [
        "tree_clf = DecisionTreeClassifier().fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfU4JK-g__Q8"
      },
      "source": [
        "cols = ['sum', 'min', 'max', 'mean', 'std', 'skew', 'kurt', 'median']\n",
        "train_data = train_data.drop(cols, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wifwaH8u-IiM"
      },
      "source": [
        "features = [i for i in train_data.columns if i not in ['ID_code', 'target']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1rE0324-IiN"
      },
      "source": [
        "tree_graph = tree.export_graphviz(tree_clf, feature_names = features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3X5p3VD-IiN"
      },
      "source": [
        "graphviz.Source(tree_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhyCAuh-IiN"
      },
      "source": [
        "pdp_goals = pdp.pdp_isolate(model=tree_clf, dataset=x_val, model_features=features, feature = 'var_81' )\n",
        "\n",
        "# plot it\n",
        "pdp.pdp_plot(pdp_goals, 'var_81')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZHLjCyJ-IiN"
      },
      "source": [
        "pdp_goals = pdp.pdp_isolate(model=tree_clf, dataset=x_val, model_features=features, feature = 'var_81' )\n",
        "\n",
        "# plot it\n",
        "pdp.pdp_plot(pdp_goals, 'var_68')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg4lSn2M-IiN"
      },
      "source": [
        "row_to_show = 5\n",
        "data_for_prediction = x_val.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\n",
        "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
        "\n",
        "\n",
        "tree_clf.predict_proba(data_for_prediction_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1xpB69A6yi"
      },
      "source": [
        "pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPGN58vfKfqy"
      },
      "source": [
        "import shap  # package used to calculate Shap values\n",
        "\n",
        "# Create object that can calculate shap values\n",
        "explainer = shap.TreeExplainer(tree_clf, )\n",
        "\n",
        "# Calculate Shap values\n",
        "shap_values = explainer.shap_values(x_val, check_additivity=False )\n",
        "\n",
        "\n",
        "\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], x_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xJKahuDR-IiO"
      },
      "source": [
        "import shap  # package used to calculate Shap values\n",
        "\n",
        "# Create object that can calculate shap values\n",
        "explainer = shap.TreeExplainer(tree_clf, )\n",
        "\n",
        "# Calculate Shap values\n",
        "shap_values = explainer.shap_values(x_val, check_additivity=False )\n",
        "\n",
        "\n",
        "shap.summary_plot(shap_values[1], x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9jMMUWL-IiO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}